#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
PAO : machine learning et clicks prediction
\end_layout

\begin_layout Author
Octave QUEFFELEC et Sandratra RASENDRASOA
\end_layout

\begin_layout Date
11/06/2017
\end_layout

\begin_layout Part
Introduction
\end_layout

\begin_layout Quotation
\begin_inset Quotes eld
\end_inset

We are drowning in information and starving for knowledge.
\begin_inset Quotes erd
\end_inset

 Rutherford D.
 Roger
\begin_inset Foot
status open

\begin_layout Plain Layout
T.Hastie, R.
 Tibshrani, J.
 Friedman, The Elements of Statistical Learning: Data Mining, Inference,
 and Prediction (Springer Verlag)
\end_layout

\end_inset

 
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Quotation
January 2009 Hal Varian, Google’s Chief Economist, tells the McKinsey Quarterly:
 “I keep saying the sexy job in the next ten years will be statisticians.
 People think I’m joking, but who would’ve guessed that computer engineers
 would’ve been the sexy job of the 1990s? The ability to take data—to be
 able to understand it, to process it, to extract value from it, to visualize
 it, to communicate it—that’s going to be a hugely important skill in the
 next decades…"
\begin_inset Foot
status open

\begin_layout Plain Layout
Gil Press, 
\begin_inset Quotes eld
\end_inset

A Very Short History Of Data Science
\begin_inset Quotes erd
\end_inset

,Forbes 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Avec l'avènement des technologies de l'information, le Data Science (ou
 science des données) est une discipline ayant pour objectif de répondre
 au besoin d'analyser des immenses ensembles de données pour en extraire
 des informations -potentiellement- utiles.
 Les applications sont nombreuses, que ce soit dans le secteur privé (la
 recommandation de séries par Netflix, les moteurs de recherche, l'analyse
 financière), le domaine médical (l'aide aux diagnostics) et bien d'autres
 encore.
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
Le but de notre PAO est de s'initier aux méthodes et algorithmes issus du
 Machine Learning.
 Pour cela, nous avons à notre disposition un jeu de données issu de la
 base de données en ligne Kaggle, qui a été créé pour répondre à la problématiqu
e suivante : déterminer un modéle pour estimer le taux de clicks(ou CTR)
 qui est une unité de mesure importante pour évaluer les publicités en ligne.
 Nous avons utilisé comme base un projet de l'université de Washington,
 en réalisant la partie pratique du projet et en ayant une réunion toutes
 les deux semaines avec nos responsables pédagogiques M.Gasso et M.Gauzere
 pour aborder ces différents points et les parties théoriques s'y référant.
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
L'ensemble du projet a été réalisé en langage Python qui est un des langages
 proposé dans le sujet de l'université de Washington.
 Nous avons notamment utilisé les librairies Numpy et Scipy pour nos algorithmes.
 Nous avons aussi dans un premier temps réalisé quelques algorithmes sous
 Matlab pour se familiariser avec les jeux de données.
 
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
Dans ce rapport, nous allons vous présenter tout d'abord les éléments théoriques
 nécessaires pour ce projet, puis l'ensemble des travaux pratiques que nous
 avons réalisé ainsi que les résultats qui y sont liés.
 Nous terminerons par une interprétation de ces résultats et une conclusion
 globale.
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Part
Partie théorique
\end_layout

\begin_layout Section
Supervised learning
\end_layout

\begin_layout Standard
Il existe plusieurs algorithmes d'appprentissage automatique(ou machine
 learning) qui se différencient par le mode d'apprentissage qu'ils utilisent.
 Dans le cadre de cette initiation, nous ne verrons qu'un mode d'apprentissage,
 mais il nous semble important de mentionner que d'autres techniques existent
 pour répondre aux différents besoins en machine learning.
 
\begin_inset Newline newline
\end_inset

L'apprentissage supervisé (ou supervised learning) est la technique d'apprentiss
age la plus commune pour répondre à des problèmes de machine learning.
 L'objectif est le suivant : 
\end_layout

\begin_layout Quotation
A partir des données 
\begin_inset Formula ${(x_{i},y_{i})\epsilon X\times Y,i=...,N}$
\end_inset

, estimer les dépendances entre X et Y.
 
\end_layout

\begin_layout Standard
On parle ici d'apprentissage supervisé (en opposition à l'apprentissage
 non-supervisé) car les 
\begin_inset Formula $y_{i}$
\end_inset

 (en pratique, il s'agira des cas déja traités et validés) permettent de
 guider le processus d'estimation.
 Un exemple concret pour différencier l'apprentissage supervisé de l'apprentissa
ge non-supervisé est présenté dans la figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "Figure 1"

\end_inset

.
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "Figure 1"

\end_inset


\begin_inset Graphics
	filename img/2-supervised-vs-unsupervised-1.png
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Apprentissage-supervisé-VS"

\end_inset

Apprentissage supervisé VS non-supervisé
\end_layout

\end_inset


\end_layout

\end_inset

En apprentissage supervisé, on sait d'avance qu'il y a exactement deux catégorie
s(cercle bleu et croix rouge), tandis qu'en apprentisage non supervisé,
 on essaie de partitionner et classer les données dans des groupes homogènes
 (en anglais, on parle aussi de clustering).
 Dans le cadre de notre projet, nous travaillons en apprentissage supervisé,
 nous possédons ainsi plusieurs jeux de données correspondants à X et Y,
 que nous préciserons dans la partie pratique.
\end_layout

\begin_layout Section
Fonction de coût
\end_layout

\begin_layout Standard
En apprentissage supervisé, l'objectif est de trouver une fonction 
\begin_inset Formula $f:X\rightarrow Y$
\end_inset

 qui permet d'estimer la valeur 
\begin_inset Formula $y$
\end_inset

 associée à 
\begin_inset Formula $x$
\end_inset

.
 On peut alors se poser la question suivante : la fonction 
\begin_inset Formula $f$
\end_inset

 que nous avons construite est-elle optimale pour résoudre notre problème
 ? 
\begin_inset Newline newline
\end_inset

On introduit alors la notion de de coût 
\begin_inset Formula $L(Y,f(X))$
\end_inset

, dont l'objectif et d'évaluer la pertinence de la prédiction réalisée par
 
\begin_inset Formula $f$
\end_inset

, et de pénaliser les erreurs.
 Dans l'idéal, on chercherait donc une fonction 
\begin_inset Formula $f$
\end_inset

 qui prédit au mieux 
\begin_inset Formula $y$
\end_inset

; en d'autres termes, une fonction 
\begin_inset Formula $f$
\end_inset

 qui minimise l'erreur entre la vérité et la valeur estimée.
 
\begin_inset Newline newline
\end_inset

D'où la fonction f telle que : 
\begin_inset Formula 
\[
R(f)=E_{X,Y}[L(Y,f(X))]
\]

\end_inset

R(f) où R est appelé le risque moyen ou erreur de généralisation.
\begin_inset Newline newline
\end_inset

Un exemple de fonction de coût et de risque moyen associé est le coût quadratiqu
e (ou moindres carrés) : 
\begin_inset Formula 
\[
L(Y,f(X))=(Y\text{−}f(X))^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
R(f)=E[(Y\text{−}f(X))^{2}]=\int(y\text{−}f(x))^{2}p(x,y)dxdy
\]

\end_inset

La fonction de coût est associé à l'ensemble Y dont on souhaite prédire
 les valeurs, et on peut distinguer deux types de problèmes en fonction
 de cet ensemble Y.
 
\end_layout

\begin_layout Enumerate
Si l'ensemble Y est un sous-ensemble de 
\begin_inset Formula $R^{d}$
\end_inset

 (donc continu), on traitera le problème comme étant un problème dit de
 régression, où les moindres carrés sont la fonction de coût usuelle.
 
\end_layout

\begin_layout Enumerate
Dans le cadre de notre projet, 
\begin_inset Formula $Y$
\end_inset

 est un ensemble discret non-ordonné (clic ou non clic, 0 ou 1 dans le jeu
 de données), il s'agit d'un problème dit de classification.
 Ici, on cherchera plutôt à approcher la fonction de coût suivante : 
\begin_inset Formula $\theta(-yf(x))$
\end_inset

où 
\begin_inset Formula $\theta$
\end_inset

 est la fonction échelon.
 
\end_layout

\begin_layout Section
Perceptron
\end_layout

\begin_layout Standard
Le perceptron est un classifieur lineaire de la forme : 
\begin_inset Formula 
\[
f(x)=\begin{cases}
1 & si<w,x>+b>0\\
0 & sinon
\end{cases},w\epsilon R^{n}
\]

\end_inset


\begin_inset Formula $w$
\end_inset

le vecteur des poids, 
\begin_inset Formula $b∈R$
\end_inset

, le biais, 
\begin_inset Formula $<w,x>$
\end_inset

, le produit scalaire entre le vecteur de poids w et le vecteur d’entrée
 x.
 
\begin_inset Formula $<w,x>+b=0$
\end_inset

 est alors l’équation de l’hyperplan affine qui sépare l’espace en 2 classes.
 Le but est donc d’entrainer notre vecteur de poids w afin de connaître
 par la suite notre fonction f qui nous permettra de prédire la classe d’un
 vecteur d’entrée x donné.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename img/perceptron1.png
	scale 40

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Perceptron
\end_layout

\end_inset


\end_layout

\end_inset

L’équation séparatrice des 2 classes n’est pas unique.
 Ici, 2 droites sont quasi-perpendiculaires l’une à l’autre mais le perceptron
 n’a aucun moyen d’en privilégier l’une au profit de l’autre.
\begin_inset Newline newline
\end_inset

Voici l’algorithme du perceptron, qui nous permet de mettre à jour à chaque
 iteration les poids w : 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename img/algo-perceptron.png
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Algorithme Perceptron
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Le perceptron peut etre vu comme un type de réseau de neurones simplifié.
 Nous avons donc voulu pour nous entrainer, implémenter en matlab puis en
 python l’algorithme.
 
\end_layout

\begin_layout Subsection
Descente de gradient
\end_layout

\begin_layout Standard
De manière générale, la descente de gradient est un algorithme cherchant
 à minimiser une fonction 
\begin_inset Formula $J(\omega_{0},\omega_{1})$
\end_inset

.
 Il pourrait dons notre cas s'agir de la fonction de coût que nous utilisons
 en régression logistique.
 Le principe général est le suivant : Soit une fonction 
\begin_inset Formula 
\[
J(\omega_{0},\omega_{1})
\]

\end_inset

on veut 
\begin_inset Formula 
\[
min_{\omega_{0},\omega_{1}}(J(\omega_{0},\omega_{1}))
\]

\end_inset


\end_layout

\begin_layout Standard
Etapes: 
\end_layout

\begin_layout Enumerate
on débute à 
\begin_inset Formula $\omega_{0},\omega_{1}$
\end_inset

 
\end_layout

\begin_layout Enumerate
on modifie les paramètres 
\begin_inset Formula $\omega_{0},\omega_{1}$
\end_inset

 pour minimiser notre fonction et arriver à un minimum.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename img/gradientdescent.png
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Descente de gradient
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Part
Implémentation
\end_layout

\begin_layout Standard
Le CTR (ou taux de clic) est une mesure cohérente pour évaluer la popularité
 d'une publicité.
 En pratique, notre objectif sera d'entraîner notre modèle pour espérer
 prédire le CTR sur un jeu de données d'environ un million d'exemples.
 
\end_layout

\begin_layout Section
Présentation du jeu de données
\end_layout

\begin_layout Subsection
Présentation générale
\end_layout

\begin_layout Standard
Les données que nous manipulons sont issues de la compétition 2012 KDD Cup
 Track 2.
 Nous avons à notre disposition 3 fichiers CSV : un fichier pour l'apprentissage
 
\begin_inset Quotes eld
\end_inset

train.txt
\begin_inset Quotes erd
\end_inset

 et deux fichiers pour la validation 
\begin_inset Quotes eld
\end_inset

test.txt
\begin_inset Quotes erd
\end_inset

 et 
\begin_inset Quotes eld
\end_inset

test_label.txt
\begin_inset Quotes erd
\end_inset

.Pour mieux visualiser les données, prenons l'exemple d'un untilisateur ayant
 réalisé une requête sur moteur de recherche et nous allons observer sur
 quelles publicités l'utilisateur a cliqué :
\end_layout

\begin_layout Enumerate
Nicolas réalise une recherche sur le 
\begin_inset Quotes eld
\end_inset

très utilisé
\begin_inset Quotes erd
\end_inset

 moteur de recherche Bing, où il a écrit la requête 
\begin_inset Quotes eld
\end_inset

perruque
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Enumerate
En plus des résultats, Bing affiche plusieurs publicités contenant des images
 et du texte (description, titre, etc ).
\end_layout

\begin_layout Enumerate
Nicolas clique alors sur la première publicité.
 
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename /home/rasendrasoa/Images/bing.png
	scale 35
	BoundingBox 0bp 0bp 1366bp 768bp
	clip

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Exemple de session
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Ces 3 étapes correspondent à une session.
 A la fin de cette session, Bing a receuillli un certain nombre d'enregistrement
 :
\end_layout

\begin_layout Standard
\begin_inset Formula $Clicked=1|Depth=10|Position=1|Nicolas|TextAd1$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $Clicked=0|Depth=10|Position=2|Nicolas|TextAd2$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $Clicked=0|Depth=10|Position=3|Nicolas|TextAd3$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $etc$
\end_inset

...
\end_layout

\begin_layout Standard
En plus de ces d'enregistrements, Bing possède d'autres informations sur
 l'utilisateur.
 Le format complet d'une ligne du jeu de données est présenté ici :
\end_layout

\begin_layout Quotation
Clicked | Depth | Position | Userid | Gender | Age | Text Tokens of Ad
\end_layout

\begin_layout Standard
Les caractéristiques sont délibérément laissé en anglais afin de rester
 cohérent avec le code présenté ci-après.
\begin_inset Newline newline
\end_inset

Nous allons maintenant présenter chacune des caractéristiques :
\end_layout

\begin_layout Description
Clicked: 0 ou 1, indique si l'utilisateur a cliqué ou non sur la publicité
 (0 non clic et 1 clic).
\end_layout

\begin_layout Description
Depth: prend une valeur dans 
\begin_inset Formula $\{1,2,...\}$
\end_inset

, indique le nombre de publicités affichées dans chaque session.
\end_layout

\begin_layout Description
Position: prend un valeur dans 
\begin_inset Formula $\{1,2,...,Depth\}$
\end_inset

,indique le rang/position de la publicité parmi les publicités affichées.
\end_layout

\begin_layout Description
Userid: l'identifiant d'un utilisateur.
\end_layout

\begin_layout Description
Gender: le genre 
\begin_inset Formula $\{-1,0,1\}$
\end_inset

d'un utilisateur : -1 homme, 1 femme et 0 inconnu.
\end_layout

\begin_layout Description
Age: prend une valeur dans 
\begin_inset Formula $\{0,1,2,3,4,5,6\}$
\end_inset

,indique la tranche d'age d'un utlisateur : 0 si inconnu, 1 si entre 
\begin_inset Formula $(0,12]$
\end_inset

,2 si entre 
\begin_inset Formula $(12,18]$
\end_inset

,3 si entre 
\begin_inset Formula $(19,24]$
\end_inset

,4 si entre 
\begin_inset Formula $(24,30]$
\end_inset

,5 si entre 
\begin_inset Formula $(30,40]$
\end_inset

et 6 si au-delà de 40.
\end_layout

\begin_layout Description
TextTokensofAd: une liste séparée par des virgules des 
\begin_inset Quotes eld
\end_inset

clés
\begin_inset Quotes erd
\end_inset

 de chaque mot d'une publicité.
 Par exemple 
\begin_inset Quotes eld
\end_inset

9,30,151
\begin_inset Quotes erd
\end_inset

 correspond aux clés des mots 
\begin_inset Quotes eld
\end_inset

mot#9
\begin_inset Quotes erd
\end_inset

,
\begin_inset Quotes erd
\end_inset

mot#30
\begin_inset Quotes erd
\end_inset

,
\begin_inset Quotes erd
\end_inset

mot#151
\begin_inset Quotes erd
\end_inset

 du dictionnaire utilisé (la correspondance avec des mots réels
\begin_inset Quotes erd
\end_inset

 n'est pas réalisé pour des soucis de confidentialité).
\end_layout

\begin_layout Standard
Voici donc un échantillon complet d'une ligne du jeu de données 
\begin_inset Quotes eld
\end_inset

train.txt
\begin_inset Quotes erd
\end_inset

 : 
\end_layout

\begin_layout Quotation
0|2|1|490234|1|3|0,133,1374,164,17005,1891,208,211,246,2527,3917,459,5705,625,85
0,8726,888,906,93
\end_layout

\begin_layout Standard
Comme on peut le constater, l'ensemble des attributs correspond ici à des
 scalaires pour faciliter le traitement.La seule différence entre le fichier
 d'apprentissage et de validation est que la première caractéristisque du
 fichier de validation 
\begin_inset Quotes eld
\end_inset

test.txt
\begin_inset Quotes erd
\end_inset

 est séparée du reste du fichier et enregistrée dans le fichier 
\begin_inset Quotes eld
\end_inset

test_label.txt
\begin_inset Quotes erd
\end_inset

.
 
\end_layout

\begin_layout Subsection
Zoom sur la représentation réelle des attributs
\end_layout

\begin_layout Standard
De manière théorique, il est facile représenter le vecteur des attributs
 :
\begin_inset Formula 
\[
x^{t}=[x_{1}^{t},...,x_{d}^{t}]
\]

\end_inset

où chaque attribut est un élément du vecteur 
\begin_inset Formula $x^{t}$
\end_inset

.
\begin_inset Newline newline
\end_inset

En pratique, la contruction de ce vecteur nécessite plusieurs prérequis
 :
\end_layout

\begin_layout Enumerate
L'attribut 
\begin_inset Quotes eld
\end_inset

Userid
\begin_inset Quotes erd
\end_inset

 ne sera pas considéré comme une caractéristique du vecteur; il ne sera
 donc pas pris en compte.
\end_layout

\begin_layout Enumerate
Les nombres présents dans la liste des tokens étant assignés de manière
 arbitraire, il est inutile de les considérer dans notre modèle.
 Il est conseillé de visualiser la liste des tokens 
\begin_inset Formula $L=l_{1},l_{2},...$
\end_inset

comme étant la représentation compacte d'un vecteur creux 
\begin_inset Formula $b$
\end_inset

où 
\begin_inset Formula $b(i)=1\forall i\epsilon L$
\end_inset

 .Ainsi les valeurs non-nulles de ce vecteur correspondent aux clés des mots
 utilisés pour décrire une publicité.
\end_layout

\begin_layout Enumerate
Le reste des attributs sera utilisé en tant que tel.
\end_layout

\begin_layout Section
Présentation des différents fichiers/classes
\end_layout

\begin_layout Standard
L’enoncé à mis a disposition un package avec differentes classes python
 afin de gerer assez facilement l’acces aux données.
 
\end_layout

\begin_layout Description
BasicAnalysis.py Permet de faire le warm up, on y calcule entre autre les
 unique users, unique tokens, ctr…
\end_layout

\begin_layout Description
DataInstance.py La classe DataInstance sectionne une instance des données
 en plusieurs attributs qui sont les differents features : clicked, depth,positi
on,id,gender,age,tokens… Cela facilite par la suite l’acces au features.
\end_layout

\begin_layout Description
DataSet.py La classe DataSet permet de charger un jeu de données et de naviguer
 entre les differentes instances à l’aide de fonction comme : hasNext(),
 nextInstance(), reset()...
\end_layout

\begin_layout Description
DummyLoader.py Sert à verifier si les données chargent correctement.
 Il print un nombre defini d’instances.
\end_layout

\begin_layout Description
LogisticRegression.py Permet d’entrainer les poids grace au training set
 et de predire sur le testing set.
\end_layout

\begin_layout Section
Warm-up
\end_layout

\begin_layout Standard
Notre premier traitement sur les données correspondra à plusieurs opérations
 simples, pour s'assurer qu'on peut correctement accéder et manipuler les
 données.
 En somme, les notions utilisés ici sont la manipulation des fichiers CSV
 en Python et l'utilisation basique des fonctionnalités de la librairie
 Numpy.
\begin_inset Newline newline
\end_inset

Nous profitons des opérations déja fournis avec le template de l'université
 de Washington pour accéder aux attributs qui nous intéressent.
\end_layout

\begin_layout Subsection
Taux de clic moyen
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
def average_ctr(self, dataset): 
\end_layout

\begin_layout Plain Layout
temp = 0 
\end_layout

\begin_layout Plain Layout
x = []
\end_layout

\begin_layout Plain Layout
while dataset.hasNext(): 
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

temp = dataset.nextInstance().clicked
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

x.append(temp)
\end_layout

\begin_layout Plain Layout
return numpy.sum(x)/dataset.size
\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
taux de clic moyen
\end_layout

\end_inset


\end_layout

\end_inset

Résultat : 
\emph on
Average CTR = 3.36552848438 %
\end_layout

\begin_layout Subsection
Nombre de tokens unique dans les données d'apprentissage
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
def uniq_tokens(self, dataset): 
\end_layout

\begin_layout Plain Layout
X =[] 
\end_layout

\begin_layout Plain Layout
instance = dataset.nextInstance() 
\end_layout

\begin_layout Plain Layout
while dataset.hasNext(): 
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

y = instance.tokens 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

# tokens uniques de la ligne i 
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

x = np.unique(y) 
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

X.append(x) 
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

instance = dataset.nextInstance() 
\end_layout

\begin_layout Plain Layout
X = np.array(x) 
\end_layout

\begin_layout Plain Layout

\emph on
# tokens uniques de X = [x1' x2' ...
 xi' ...
 xn']' 
\end_layout

\begin_layout Plain Layout
X = np.unique(X)
\end_layout

\begin_layout Plain Layout
return X
\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Nombre de tokens unique
\end_layout

\end_inset


\end_layout

\end_inset

Résultat : 
\emph on
there are 24 unique tokens 
\end_layout

\begin_layout Quotation
X
\begin_inset Formula $_{unique}$
\end_inset

 = [ 1 3 26 144 149 178 255 440 466 582 685 771 1181 1691 1766 2854 5838
 5977 6800 8511 8833 9930 10948 15645]
\end_layout

\begin_layout Section
Implémentation du perceptron
\end_layout

\begin_layout Subsection
Matlab
\end_layout

\begin_layout Standard
Nous avons implementé differents systemes assez simple.
 
\begin_inset Newline newline
\end_inset

Pour chaque systeme, nous avons gardé la meme notation : 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $l$
\end_inset

:le nombre d’entree 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $n$
\end_inset

:la dimension des entrées 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $X=[x1,x2,...,xl]$
\end_inset

, on concatene les l données dans X 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $x_{i}=[a_{1},a_{2},...,a_{n},1]$
\end_inset

on concatene le biais a la fin de chaque vecteur d’entrée 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $y=[1,-1,1,...]∈R^{l}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
w1=zeros(n+1,1); 
\end_layout

\begin_layout Plain Layout
k=0; 
\end_layout

\begin_layout Plain Layout
K=67; 
\end_layout

\begin_layout Plain Layout
for compteur=1:K 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
indice=randperm(l); 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
for i=1:l i=indice(i); 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
if(y(i)*(x(i,:)*w1)<=0) 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
w1=w1+y(i)*x(i,:)'; 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
k=k+1; 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
end 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
end 
\end_layout

\begin_layout Plain Layout
end
\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
perceptron sous matlab
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Python
\end_layout

\begin_layout Standard
Nous avons ensuite implementé le perceptron en python, afin de nous familiariser
 avec les librairies numpy, math, et matplotlib.
 Les résultats obtenus sont identiques à ceux en matlab.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
l = np.size(x[:,1]) 
\end_layout

\begin_layout Plain Layout
for count in range(1,k): 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
indice = np.random.permutation(range(l)) 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
for i in range(1,l): 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
i = indice[i] 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
if(np.dot(y[i],np.inner(x[i,:],w))<=0): 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
w += np.dot(y[i],x[i,:])
\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
perceptron en python
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Résultats pour les différents systèmes :
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename img/systOR.png
	scale 35

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Système OR
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename img/systAND.png
	scale 35

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Système AND
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename img/syst2classe.png
	scale 35

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
2 classes séparables
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename img/syst2classemuch.png
	scale 35

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
plusieurs solutions pour 2 classes séparables
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Descente de gradient stochastique (SGD)
\end_layout

\begin_layout Standard
L'objectif de la descente de gradient stochastique est de réaliser une estimatio
n du 
\begin_inset Quotes eld
\end_inset

vrai
\begin_inset Quotes erd
\end_inset

 gradient en ne mettant à jour que ce qui nous intéresse.
 Le principe est le suivant :
\end_layout

\begin_layout Enumerate
Choisir un vecteur initial de paramètres 
\begin_inset Formula $\omega$
\end_inset

, et un taux d'apprentissage 
\begin_inset Formula $η$
\end_inset

.
\end_layout

\begin_layout Enumerate
Répéter jusqu'à ce qu'un minimum approché (assez précisément) soit obtenu
 :
\end_layout

\begin_layout Enumerate
Mélanger aléatoirement les échantillons de l'ensemble d'apprentissage.
 
\end_layout

\begin_layout Enumerate
Pour 
\begin_inset Formula $i=1,2,...,n$
\end_inset

 faire : 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\omega=\omega−η∇Qi(w)$
\end_inset


\end_layout

\begin_layout Standard
Dans le projet, le vecteur de paramètres
\begin_inset Formula $\omega$
\end_inset

 est une classe nommée Weights, possédant qui possèdent plusiers paramètres
 :
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
# This class represents the weights in the logistic regression model.
 
\end_layout

\begin_layout Plain Layout
class Weights: 
\end_layout

\begin_layout Plain Layout
def __init__(self): 
\end_layout

\begin_layout Plain Layout
self.w0 = self.w_age = self.w_gender = self.w_depth = self.w_position = 0 
\end_layout

\begin_layout Plain Layout
# token feature weights 
\end_layout

\begin_layout Plain Layout
self.w_tokens = np.zeros(shape=(1070659,1)) 
\end_layout

\begin_layout Plain Layout
# to keep track of the access timestamp of feature weights.
 
\end_layout

\begin_layout Plain Layout
# use this to do delayed regularization.
 self.access_time = {}
\end_layout

\begin_layout Plain Layout
def __str__(self): 
\end_layout

\begin_layout Plain Layout
formatter = "{0:.2f}" 
\end_layout

\begin_layout Plain Layout
string = "" 
\end_layout

\begin_layout Plain Layout
string += "Intercept: " + formatter.format(self.w0) + "
\backslash
n" 
\end_layout

\begin_layout Plain Layout
string += "Depth: " + formatter.format(self.w_depth) + "
\backslash
n" 
\end_layout

\begin_layout Plain Layout
string += "Position: " + formatter.format(self.w_position) + "
\backslash
n" 
\end_layout

\begin_layout Plain Layout
string += "Gender: " + formatter.format(self.w_gender) + "
\backslash
n" 
\end_layout

\begin_layout Plain Layout
string += "Age: " + formatter.format(self.w_age) + "
\backslash
n" 
\end_layout

\begin_layout Plain Layout
string += "Tokens: " + str(self.w_tokens) + "
\backslash
n" 
\end_layout

\begin_layout Plain Layout
return string
\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Classe Weights
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Itemize
La mise à jour des paramètres 
\begin_inset Formula $\omega$
\end_inset

est réalisé dans la fonction 
\emph on
train(self, dataset, lambduh, step, avg_loss).
 
\emph default
Cette fonction retourne les paramètres mis à jour ainsi que la courbe d'erreur
 cumulative.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
def train(self, dataset, lambduh, step, avg_loss): 
\end_layout

\begin_layout Plain Layout
N = dataset.size 
\end_layout

\begin_layout Plain Layout
weights= Weights() 
\end_layout

\begin_layout Plain Layout
n_epoch = 1 
\end_layout

\begin_layout Plain Layout
N00=0 
\end_layout

\begin_layout Plain Layout
N01=0 
\end_layout

\begin_layout Plain Layout
N10=0 
\end_layout

\begin_layout Plain Layout
N11=0 
\end_layout

\begin_layout Plain Layout
count = 0 
\end_layout

\begin_layout Plain Layout
nbStep = 100 
\end_layout

\begin_layout Plain Layout
T = np.linspace(0,N,N/nbStep) 
\end_layout

\begin_layout Plain Layout
for epoch in range(n_epoch): 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
while (dataset.hasNext()): 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
instance = dataset.nextInstance() 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
prediction = self.predict(weights, instance) 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
error = instance.clicked - prediction 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
if(error==0): 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
if(prediction==0): 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
N00+=1 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
else: 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
N11+=1 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
else: 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
if(prediction==0): 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
N10+=1 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
else: 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
N01+=1 
\end_layout

\begin_layout Plain Layout
# if (error!=0):
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
weights.w0 = weights.w0 + step * error 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
weights.w_age = weights.w_age + step * error * instance.age 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
weights.w_gender = weights.w_gender + step * error * instance.gender 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
weights.w_depth = weights.w_depth + step * error * instance.depth 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
weights.w_position = weights.w_position + step * error * instance.position
 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
for indice in instance.tokens: 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
weights.w_tokens[indice]= weights.w_tokens[indice]+step*error 
\end_layout

\begin_layout Plain Layout
# record the average loss for each step 100 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
avg_loss[0] = (1 / 2) * (error * error) 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
j = count % nbStep 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
if (j == 0 and count / nbStep != 0): 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
avg_loss[int(count / nbStep)] = (1 / (2 * count)) * (error * error) + avg_loss[i
nt(count / nbStep) - 1] 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
count += 1
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
print("train DONE") 
\end_layout

\begin_layout Plain Layout
return weights,N00,N10,N01,N11,T,avg_loss
\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
simple train
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Régularisation
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
def regularised_train(self, dataset, lambduh, step, avg_loss):
\end_layout

\begin_layout Plain Layout
#---même chose que le simple train---
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
weights.w0 = (1-step*lambduh/N)*weights.w0 + step * error 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
weights.w_age = (1-step*lambduh/N)*weights.w_age + step * error * instance.age
 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
weights.w_gender = (1-step*lambduh/N)*weights.w_gender + step * error * instance.ge
nder 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
weights.w_depth = (1-step*lambduh/N)*weights.w_depth + step * error * instance.dept
h 
\end_layout

\begin_layout Plain Layout

\emph on
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph default
weights.w_position = (1-step*lambduh/N)*weights.w_position + step * error
 * instance.position 
\end_layout

\begin_layout Plain Layout
#---même chose que le simple train---
\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
regularized train
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize
logreg
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
def sigmoid(self,z): 
\end_layout

\begin_layout Plain Layout
return 1/(1+math.exp(-1*z))
\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
sigmoïde
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Plain Layout
def regularised_train(self, dataset, lambduh, step, avg_loss):
\end_layout

\begin_layout Plain Layout
#---même chose que le regularized train---
\end_layout

\begin_layout Plain Layout
prediction =self.sigmoid(self.compute_weight_feature_product(weights,instance))
\end_layout

\begin_layout Plain Layout
#---même chose que le regularized train---
\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
logreg
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Part
Evaluation du modèle
\end_layout

\begin_layout Standard
L'évaluation est réalisée pour 
\begin_inset Formula $\lambda=\{0.01\}$
\end_inset

pour la régularisation et le logreg.
\end_layout

\begin_layout Subsection
Matrice de confusion
\end_layout

\begin_layout Subsubsection
Apprentissage simple
\end_layout

\begin_layout Standard
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="3">
<features rotate="0" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Prédiction ŷ / Vérité y
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Positifs
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Négatifs
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Positifs
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
45978
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1906
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Négatifs
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1916
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
200
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Itemize
Ratio de reussite pour le training 0.92356 
\end_layout

\begin_layout Itemize
Average ctr for training 0.04212 
\end_layout

\begin_layout Itemize
Average ctr for training predicted 0.04232
\end_layout

\begin_layout Subsubsection
Régularisation
\end_layout

\begin_layout Standard
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="3">
<features rotate="0" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Prédiction ŷ / Vérité y
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Positifs
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Négatifs
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Positifs
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
45989
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1898
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Négatifs
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1905
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
208
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Itemize
Ratio de reussite pour le training 0.92394 
\end_layout

\begin_layout Itemize
Average ctr for training 0.04212 
\end_layout

\begin_layout Itemize
Average ctr for training predicted 0.04226
\end_layout

\begin_layout Subsubsection
LogRegression
\end_layout

\begin_layout Standard
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="3">
<features rotate="0" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Prédiction ŷ / Vérité y
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Positifs
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Négatifs
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Positifs
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
45989
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1898
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Négatifs
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1905
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
208
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Itemize
Ratio de reussite pour le training 0.92394 
\end_layout

\begin_layout Itemize
Average ctr for training 0.04212 
\end_layout

\begin_layout Itemize
Average ctr for training predicted 0.04226
\end_layout

\end_body
\end_document
